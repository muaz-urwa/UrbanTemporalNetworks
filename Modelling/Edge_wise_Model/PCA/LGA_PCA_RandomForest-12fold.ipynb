{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.multioutput import MultiOutputRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(file):\n",
    "    data = pd.read_csv(file)\n",
    "    print('Raw shape: ',data.shape)\n",
    "    data['Date'] = pd.to_datetime(data.Date)\n",
    "    print('Days: ',len(set(data.Date)))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTimeSeries(df):\n",
    "    table = pd.pivot_table(df, values='vehicle_count', index=['Date','Hour'],\n",
    "                    columns=['DOLocationID'], aggfunc=np.sum, fill_value=0)\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscoreNormalizeSpatial(matrix):\n",
    "    m = matrix.copy()\n",
    "    for i in range(m.shape[0]):\n",
    "        m[i, :] = (m[i, :] - m[i, :].mean()) / (m[i, :].std()+1e-10)\n",
    "        \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(matrix):\n",
    "    m = matrix.copy()\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(m)\n",
    "    t = scaler.transform(m)\n",
    "    return scaler, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_standardize(matrix, scaler):\n",
    "    t = matrix.copy()\n",
    "    return scaler.inverse_transform(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPCAFeatures(matrix, n=10):\n",
    "    pca = PCA(n_components=n)\n",
    "    pca.fit(matrix)\n",
    "    reducedMatrixPCA = pca.transform(matrix)\n",
    "    reducedMatrixPCA.shape\n",
    "\n",
    "    reducedDict = {str(i+1):reducedMatrixPCA[:,i] for i in range(reducedMatrixPCA.shape[1])}\n",
    "    reducedDf = pd.DataFrame(reducedDict)\n",
    "    #reducedDf.index = index\n",
    "    return pca,reducedDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_test(matrix, pca):\n",
    "\n",
    "    reducedMatrixPCA = pca.transform(matrix)\n",
    "\n",
    "    reducedDict = {str(i+1):reducedMatrixPCA[:,i] for i in range(reducedMatrixPCA.shape[1])}\n",
    "    reducedDf = pd.DataFrame(reducedDict)\n",
    "    #reducedDf.index = index\n",
    "    return reducedDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_pca(matrix,pca):\n",
    "    m = matrix.copy()\n",
    "    return pca.inverse_transform(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addLag(dataset, maxlag, lagColumns):\n",
    "    dataset_list = [dataset]\n",
    "\n",
    "    for l in range(1, maxlag+1):\n",
    "        df = dataset.shift(l)\n",
    "        df = df[lagColumns]\n",
    "        df.columns = [c+'_lag_'+str(l) for c in df.columns]\n",
    "        dataset_list.append(df)\n",
    "\n",
    "    dataset = pd.concat(dataset_list, axis=1).dropna()\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmse(matrix1, matrix2):\n",
    "    sumSquareError = np.mean(np.power(matrix1 - matrix2,2))\n",
    "    rmse = np.power(sumSquareError,0.5)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_performance(trainmatrix,testmatrix, components):\n",
    "    rmseList = []\n",
    "    r2List = []\n",
    "    for n in components:\n",
    "        scaler, s_train_matrix = standardize(trainmatrix)\n",
    "        s_test_matrix = scaler.transform(testmatrix)\n",
    "\n",
    "        pca,pcaTrain = getPCAFeatures(s_train_matrix,n=n)\n",
    "        pcaTest = PCA_test(s_test_matrix, pca)\n",
    "        \n",
    "        network_prediction = inverse_pca(pcaTest,pca)\n",
    "        network_prediction = inverse_standardize(network_prediction, scaler)\n",
    "\n",
    "        r2Score = r2_score(testmatrix, network_prediction, multioutput='variance_weighted')\n",
    "                \n",
    "        r2List.append(r2Score)\n",
    "    \n",
    "    return r2List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonlinearperformance(trainmatrix,testmatrix,components, maxlag=12):\n",
    "    r2List = []\n",
    "    for n in components:\n",
    "        print(n)\n",
    "        scaler, s_train_matrix = standardize(trainmatrix)\n",
    "        s_test_matrix = scaler.transform(testmatrix)\n",
    "\n",
    "        pca,pcaTrain = getPCAFeatures(s_train_matrix,n=n)\n",
    "        pcaTest = PCA_test(s_test_matrix, pca)\n",
    "\n",
    "#         maxlag = 12\n",
    "        DateColumns = ['Date', 'Hour']\n",
    "        lagColumns = [c for c in pcaTrain.columns if c not in DateColumns]\n",
    "\n",
    "        dataset_train = addLag(pcaTrain, maxlag)\n",
    "\n",
    "        dataset_test = addLag(pcaTest, maxlag)\n",
    "\n",
    "        X_train = dataset_train.drop(lagColumns , axis = 1)\n",
    "        X_test = dataset_test.drop(lagColumns , axis = 1)\n",
    "        y_train = dataset_train[lagColumns]\n",
    "        y_test = dataset_test[lagColumns]\n",
    "#         print(X_train.shape)\n",
    "#         print(X_test.shape)\n",
    "#         print(y_train.shape)\n",
    "#         print(y_test.shape)\n",
    "\n",
    "        rf2 = RandomForestRegressor(random_state = 0, n_estimators=200, \n",
    "                                   min_samples_split=10,\n",
    "                                   min_samples_leaf= 3, \n",
    "                                   max_features= 'sqrt',\n",
    "                                   max_depth= 30, \n",
    "                                   bootstrap= True)\n",
    "\n",
    "        rf2.fit(X_train,y_train)\n",
    "\n",
    "        pca_prediction = rf2.predict(X_test)\n",
    "\n",
    "        network_prediction = inverse_pca(pca_prediction,pca)\n",
    "\n",
    "        network_prediction = inverse_standardize(network_prediction, scaler)\n",
    "\n",
    "        r2Score = r2_score(testmatrix[maxlag:], network_prediction, \\\n",
    "                           multioutput='variance_weighted')\n",
    "        \n",
    "        r2List.append(r2Score)\n",
    "    return r2List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hub = 'Lga'\n",
    "tune_hyp_params = False\n",
    "pca_comps = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = '/home/urwa/Documents/Projects/NYU Remote/project/data/processedData/'\n",
    "file = dataDir + hub + 'VehiceByHour.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = '/home/urwa/Documents/Projects/NYU Remote/project/data/JfkVehiceByHour.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw shape:  (2251320, 4)\n",
      "Days:  365\n"
     ]
    }
   ],
   "source": [
    "data = loadData(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = getTimeSeries(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8760, 257)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = data.values.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler, s_matrix = standardize(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca,pcaData = getPCAFeatures(s_matrix,n=pca_comps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcaData.index = data.index\n",
    "pcaData = pcaData.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "externalDataDir = \"/home/urwa/Documents/Projects/NYU Remote/project/data/HongData/\"\n",
    "extFile = externalDataDir + hub.upper() + \".csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8760, 46)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>arrival</th>\n",
       "      <th>fhv</th>\n",
       "      <th>yellow</th>\n",
       "      <th>vehicle</th>\n",
       "      <th>ifmon</th>\n",
       "      <th>iftue</th>\n",
       "      <th>ifwed</th>\n",
       "      <th>ifthu</th>\n",
       "      <th>iffri</th>\n",
       "      <th>...</th>\n",
       "      <th>maxtemp</th>\n",
       "      <th>mintemp</th>\n",
       "      <th>avgtemp</th>\n",
       "      <th>departure</th>\n",
       "      <th>hdd</th>\n",
       "      <th>cdd</th>\n",
       "      <th>participation</th>\n",
       "      <th>newsnow</th>\n",
       "      <th>snowdepth</th>\n",
       "      <th>ifSnow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18/1/1 0:00</td>\n",
       "      <td>3</td>\n",
       "      <td>89</td>\n",
       "      <td>67</td>\n",
       "      <td>156</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>13.5</td>\n",
       "      <td>-20.5</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18/1/1 1:00</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>13.5</td>\n",
       "      <td>-20.5</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  arrival  fhv  yellow  vehicle  ifmon  iftue  ifwed  ifthu  \\\n",
       "0  18/1/1 0:00        3   89      67      156      1      0      0      0   \n",
       "1  18/1/1 1:00        0   17       8       25      1      0      0      0   \n",
       "\n",
       "   iffri   ...    maxtemp  mintemp  avgtemp  departure  hdd  cdd  \\\n",
       "0      0   ...         19        8     13.5      -20.5   51    0   \n",
       "1      0   ...         19        8     13.5      -20.5   51    0   \n",
       "\n",
       "   participation  newsnow  snowdepth  ifSnow  \n",
       "0            0.0      0.0          0       0  \n",
       "1            0.0      0.0          0       0  \n",
       "\n",
       "[2 rows x 46 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extDf = pd.read_csv(extFile)\n",
    "print(extDf.shape)\n",
    "extDf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>arrival</th>\n",
       "      <th>fhv</th>\n",
       "      <th>yellow</th>\n",
       "      <th>vehicle</th>\n",
       "      <th>ifmon</th>\n",
       "      <th>iftue</th>\n",
       "      <th>ifwed</th>\n",
       "      <th>ifthu</th>\n",
       "      <th>iffri</th>\n",
       "      <th>...</th>\n",
       "      <th>maxtemp</th>\n",
       "      <th>mintemp</th>\n",
       "      <th>avgtemp</th>\n",
       "      <th>departure</th>\n",
       "      <th>hdd</th>\n",
       "      <th>cdd</th>\n",
       "      <th>participation</th>\n",
       "      <th>newsnow</th>\n",
       "      <th>snowdepth</th>\n",
       "      <th>ifSnow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>89</td>\n",
       "      <td>67</td>\n",
       "      <td>156</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>13.5</td>\n",
       "      <td>-20.5</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 01:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>13.5</td>\n",
       "      <td>-20.5</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date  arrival  fhv  yellow  vehicle  ifmon  iftue  ifwed  \\\n",
       "0 2018-01-01 00:00:00        3   89      67      156      1      0      0   \n",
       "1 2018-01-01 01:00:00        0   17       8       25      1      0      0   \n",
       "\n",
       "   ifthu  iffri   ...    maxtemp  mintemp  avgtemp  departure  hdd  cdd  \\\n",
       "0      0      0   ...         19        8     13.5      -20.5   51    0   \n",
       "1      0      0   ...         19        8     13.5      -20.5   51    0   \n",
       "\n",
       "   participation  newsnow  snowdepth  ifSnow  \n",
       "0            0.0      0.0          0       0  \n",
       "1            0.0      0.0          0       0  \n",
       "\n",
       "[2 rows x 46 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extDf['date'] = pd.to_datetime(extDf['date'], yearfirst=True)\n",
    "extDf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "extDf['Hour'] = extDf['date'].dt.hour\n",
    "extDf['Dow'] = extDf['date'].dt.dayofweek\n",
    "extDf['Date'] = extDf['date'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'arrival', 'fhv', 'yellow', 'vehicle', 'ifmon', 'iftue',\n",
       "       'ifwed', 'ifthu', 'iffri', 'ifsat', 'ifsun', 'if0', 'if1', 'if2', 'if3',\n",
       "       'if4', 'if5', 'if6', 'if7', 'if8', 'if9', 'if10', 'if11', 'if12',\n",
       "       'if13', 'if14', 'if15', 'if16', 'if17', 'if18', 'if19', 'if20', 'if21',\n",
       "       'if22', 'if23', 'maxtemp', 'mintemp', 'avgtemp', 'departure', 'hdd',\n",
       "       'cdd', 'participation', 'newsnow', 'snowdepth', 'ifSnow', 'Hour', 'Dow',\n",
       "       'Date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extDf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['Date', 'Hour', 'Dow', 'arrival','maxtemp', 'mintemp', 'avgtemp', 'departure', 'hdd',\n",
    "       'cdd', 'participation', 'newsnow', 'snowdepth', 'ifSnow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "extDf = extDf[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8760, 26)\n",
      "(8760, 14)\n"
     ]
    }
   ],
   "source": [
    "print(pcaData.shape)\n",
    "print(extDf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcaData['Date'] = pd.to_datetime(pcaData['Date'])\n",
    "extDf['Date'] = pd.to_datetime(extDf['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8760, 38)\n"
     ]
    }
   ],
   "source": [
    "pcaData = pd.merge(pcaData,extDf, on=['Date', 'Hour'], how='inner')\n",
    "print(pcaData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Hour', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11',\n",
       "       '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23',\n",
       "       '24', 'Dow', 'arrival', 'maxtemp', 'mintemp', 'avgtemp', 'departure',\n",
       "       'hdd', 'cdd', 'participation', 'newsnow', 'snowdepth', 'ifSnow'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcaData.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lagColumns = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11',\n",
    "       '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23',\n",
    "       '24', 'arrival']\n",
    "# lagColumns = ['1', '2', '3', 'arrival']\n",
    "\n",
    "DateColumns = ['Date']\n",
    "\n",
    "targetColumns = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11',\n",
    "       '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23',\n",
    "       '24']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8748, 338)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlag = 12\n",
    "\n",
    "pcaData_lag = addLag(pcaData, maxlag, lagColumns)\n",
    "\n",
    "pcaData_lag.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "month:  1\n",
      "Train Size:  (8016, 338)\n",
      "Test Size:  (732, 338)\n",
      "Train R2:  0.9537765158445664\n",
      "Test R2:  0.6669872937147757\n",
      "Edge R2:  0.7423186374200783\n",
      "\n",
      "month:  2\n",
      "Train Size:  (8076, 338)\n",
      "Test Size:  (672, 338)\n",
      "Train R2:  0.9532805932774798\n",
      "Test R2:  0.7153675904677854\n",
      "Edge R2:  0.7669530659394754\n",
      "\n",
      "month:  3\n",
      "Train Size:  (8004, 338)\n",
      "Test Size:  (744, 338)\n",
      "Train R2:  0.9529786020746097\n",
      "Test R2:  0.7458562664643983\n",
      "Edge R2:  0.7783416199969865\n",
      "\n",
      "month:  4\n",
      "Train Size:  (8028, 338)\n",
      "Test Size:  (720, 338)\n",
      "Train R2:  0.9532902397178363\n",
      "Test R2:  0.7105656445666985\n",
      "Edge R2:  0.7870231995968515\n",
      "\n",
      "month:  5\n",
      "Train Size:  (8004, 338)\n",
      "Test Size:  (744, 338)\n",
      "Train R2:  0.9531848561790246\n",
      "Test R2:  0.7241976134639335\n",
      "Edge R2:  0.7923491675750818\n",
      "\n",
      "month:  6\n",
      "Train Size:  (8028, 338)\n",
      "Test Size:  (720, 338)\n",
      "Train R2:  0.9539321019259851\n",
      "Test R2:  0.6860602717392672\n",
      "Edge R2:  0.7812349686337599\n",
      "\n",
      "month:  7\n",
      "Train Size:  (8004, 338)\n",
      "Test Size:  (744, 338)\n",
      "Train R2:  0.9538640276885174\n",
      "Test R2:  0.6674256781384063\n",
      "Edge R2:  0.7536421326069258\n",
      "\n",
      "month:  8\n",
      "Train Size:  (8004, 338)\n",
      "Test Size:  (744, 338)\n",
      "Train R2:  0.9540785749739499\n",
      "Test R2:  0.642749216714701\n",
      "Edge R2:  0.7340910896673355\n",
      "\n",
      "month:  9\n",
      "Train Size:  (8028, 338)\n",
      "Test Size:  (720, 338)\n",
      "Train R2:  0.9533174768328249\n",
      "Test R2:  0.7242014858976403\n",
      "Edge R2:  0.7689023904162626\n",
      "\n",
      "month:  10\n",
      "Train Size:  (8004, 338)\n",
      "Test Size:  (744, 338)\n",
      "Train R2:  0.9531756111009193\n",
      "Test R2:  0.7284065564189428\n",
      "Edge R2:  0.7965480637421753\n",
      "\n",
      "month:  11\n",
      "Train Size:  (8028, 338)\n",
      "Test Size:  (720, 338)\n",
      "Train R2:  0.9526303128431506\n",
      "Test R2:  0.6990830215214254\n",
      "Edge R2:  0.7480278574722729\n",
      "\n",
      "month:  12\n",
      "Train Size:  (8004, 338)\n",
      "Test Size:  (744, 338)\n",
      "Train R2:  0.9531009317005157\n",
      "Test R2:  0.7165329859016109\n",
      "Edge R2:  0.7392956385244729\n"
     ]
    }
   ],
   "source": [
    "CommR2List = []\n",
    "EdgeR2List = []\n",
    "residualDf_list = []\n",
    "\n",
    "for m in range(1,13):\n",
    "    print()\n",
    "\n",
    "    print(\"month: \",m)\n",
    "    month_index  = pd.to_datetime(pcaData_lag.Date).dt.month == m\n",
    "\n",
    "    dataset_train = pcaData_lag[~month_index]\n",
    "    dataset_test = pcaData_lag[month_index]\n",
    "    print(\"Train Size: \",dataset_train.shape)\n",
    "    print(\"Test Size: \",dataset_test.shape)\n",
    "\n",
    "\n",
    "    X_train = dataset_train.drop(targetColumns+DateColumns , axis = 1)\n",
    "    X_test = dataset_test.drop(targetColumns+DateColumns , axis = 1)\n",
    "    y_train = dataset_train[targetColumns]\n",
    "    y_test = dataset_test[targetColumns]\n",
    "\n",
    "\n",
    "\n",
    "    rf2 = RandomForestRegressor(random_state = 2019, n_estimators=150, \n",
    "                               min_samples_split=3,\n",
    "                               min_samples_leaf= 2, \n",
    "                               max_features= 'sqrt',\n",
    "                               max_depth= None, \n",
    "                               bootstrap= False)\n",
    "\n",
    "    rf2.fit(X_train,y_train)\n",
    "\n",
    "    print(\"Train R2: \",rf2.score(X_train,y_train))\n",
    "    test_r2 = rf2.score(X_test,y_test)\n",
    "    print(\"Test R2: \",test_r2)\n",
    "\n",
    "\n",
    "    pca_prediction = rf2.predict(X_test)\n",
    "\n",
    "    residual = y_test - pca_prediction\n",
    "    residual_df = dataset_test[['Date','Hour']]\n",
    "    residual_df = pd.concat([residual_df,pd.DataFrame(residual)], axis =1)\n",
    "\n",
    "    network_prediction = inverse_pca(pca_prediction,pca)\n",
    "\n",
    "    network_prediction = inverse_standardize(network_prediction, scaler)\n",
    "\n",
    "    edgeMonthIndex = [False] * maxlag + list(month_index)\n",
    "    edge_r2 = r2_score(data[edgeMonthIndex], network_prediction, multioutput='variance_weighted')\n",
    "    print(\"Edge R2: \",edge_r2)\n",
    "\n",
    "\n",
    "    CommR2List.append(test_r2)\n",
    "    EdgeR2List.append(edge_r2)\n",
    "    residualDf_list.append(residual_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7022861354174653\n",
      "0.7657273192993065\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(CommR2List))\n",
    "print(np.mean(EdgeR2List))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8748, 26)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Hour</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>12</td>\n",
       "      <td>-1.276498</td>\n",
       "      <td>-1.418360</td>\n",
       "      <td>-0.734761</td>\n",
       "      <td>0.433334</td>\n",
       "      <td>0.847615</td>\n",
       "      <td>0.600153</td>\n",
       "      <td>-0.309384</td>\n",
       "      <td>0.903964</td>\n",
       "      <td>...</td>\n",
       "      <td>0.971311</td>\n",
       "      <td>-0.678664</td>\n",
       "      <td>0.060925</td>\n",
       "      <td>0.781666</td>\n",
       "      <td>1.411823</td>\n",
       "      <td>-1.285399</td>\n",
       "      <td>-0.347982</td>\n",
       "      <td>0.451313</td>\n",
       "      <td>-0.361053</td>\n",
       "      <td>2.445438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>13</td>\n",
       "      <td>-1.409846</td>\n",
       "      <td>-1.548568</td>\n",
       "      <td>-2.361757</td>\n",
       "      <td>1.056336</td>\n",
       "      <td>-0.301393</td>\n",
       "      <td>-0.659736</td>\n",
       "      <td>0.328668</td>\n",
       "      <td>0.238655</td>\n",
       "      <td>...</td>\n",
       "      <td>1.081474</td>\n",
       "      <td>-0.632221</td>\n",
       "      <td>0.854535</td>\n",
       "      <td>2.004912</td>\n",
       "      <td>-0.984908</td>\n",
       "      <td>-2.257620</td>\n",
       "      <td>0.846469</td>\n",
       "      <td>0.222759</td>\n",
       "      <td>-0.465578</td>\n",
       "      <td>-0.859855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>14</td>\n",
       "      <td>-0.138244</td>\n",
       "      <td>-1.537126</td>\n",
       "      <td>-2.708636</td>\n",
       "      <td>0.106917</td>\n",
       "      <td>-0.260874</td>\n",
       "      <td>-0.902172</td>\n",
       "      <td>-1.563087</td>\n",
       "      <td>0.998505</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.905526</td>\n",
       "      <td>0.048317</td>\n",
       "      <td>0.853647</td>\n",
       "      <td>0.195555</td>\n",
       "      <td>0.002670</td>\n",
       "      <td>-0.863667</td>\n",
       "      <td>-1.354411</td>\n",
       "      <td>-0.143623</td>\n",
       "      <td>-1.516680</td>\n",
       "      <td>1.047018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>15</td>\n",
       "      <td>1.703857</td>\n",
       "      <td>-1.693059</td>\n",
       "      <td>-2.843108</td>\n",
       "      <td>1.100942</td>\n",
       "      <td>-2.205084</td>\n",
       "      <td>0.216938</td>\n",
       "      <td>1.796747</td>\n",
       "      <td>0.041086</td>\n",
       "      <td>...</td>\n",
       "      <td>0.293858</td>\n",
       "      <td>0.190559</td>\n",
       "      <td>1.007963</td>\n",
       "      <td>1.018427</td>\n",
       "      <td>-0.542907</td>\n",
       "      <td>-1.093309</td>\n",
       "      <td>0.971033</td>\n",
       "      <td>-0.053084</td>\n",
       "      <td>0.247304</td>\n",
       "      <td>-1.082951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>16</td>\n",
       "      <td>-1.994186</td>\n",
       "      <td>-0.574273</td>\n",
       "      <td>-4.242602</td>\n",
       "      <td>-0.515221</td>\n",
       "      <td>-0.553907</td>\n",
       "      <td>-0.072020</td>\n",
       "      <td>-0.997730</td>\n",
       "      <td>0.570433</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.063358</td>\n",
       "      <td>-0.027308</td>\n",
       "      <td>-1.236365</td>\n",
       "      <td>0.181270</td>\n",
       "      <td>1.408685</td>\n",
       "      <td>-0.469710</td>\n",
       "      <td>-0.789398</td>\n",
       "      <td>0.342445</td>\n",
       "      <td>0.402248</td>\n",
       "      <td>-0.748757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Hour         1         2         3         4         5  \\\n",
       "12 2018-01-01    12 -1.276498 -1.418360 -0.734761  0.433334  0.847615   \n",
       "13 2018-01-01    13 -1.409846 -1.548568 -2.361757  1.056336 -0.301393   \n",
       "14 2018-01-01    14 -0.138244 -1.537126 -2.708636  0.106917 -0.260874   \n",
       "15 2018-01-01    15  1.703857 -1.693059 -2.843108  1.100942 -2.205084   \n",
       "16 2018-01-01    16 -1.994186 -0.574273 -4.242602 -0.515221 -0.553907   \n",
       "\n",
       "           6         7         8    ...           15        16        17  \\\n",
       "12  0.600153 -0.309384  0.903964    ...     0.971311 -0.678664  0.060925   \n",
       "13 -0.659736  0.328668  0.238655    ...     1.081474 -0.632221  0.854535   \n",
       "14 -0.902172 -1.563087  0.998505    ...    -0.905526  0.048317  0.853647   \n",
       "15  0.216938  1.796747  0.041086    ...     0.293858  0.190559  1.007963   \n",
       "16 -0.072020 -0.997730  0.570433    ...    -1.063358 -0.027308 -1.236365   \n",
       "\n",
       "          18        19        20        21        22        23        24  \n",
       "12  0.781666  1.411823 -1.285399 -0.347982  0.451313 -0.361053  2.445438  \n",
       "13  2.004912 -0.984908 -2.257620  0.846469  0.222759 -0.465578 -0.859855  \n",
       "14  0.195555  0.002670 -0.863667 -1.354411 -0.143623 -1.516680  1.047018  \n",
       "15  1.018427 -0.542907 -1.093309  0.971033 -0.053084  0.247304 -1.082951  \n",
       "16  0.181270  1.408685 -0.469710 -0.789398  0.342445  0.402248 -0.748757  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df = pd.concat(residualDf_list, axis = 0)\n",
    "print(res_df.shape)\n",
    "res_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.to_csv('/home/urwa/Documents/Projects/NYU Remote/project/data/residuals/lga_pca24.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
